Привет, я Себастьян Аалтонен. У меня более 20 лет опыта в графическом программировании. В прошлом я работал в Ubisoft и Unity, создавая их кроссплатформенные технологии рендеринга.

Я присоединился к HypeHype год назад с целью переписать их технологию мобильного рендеринга. Сегодня я расскажу о первой вехе этого проекта: переписывании низкоуровневого графического API и бэкэндов платформы.
_;
HypeHype — это платформа для разработки мобильных игр. Вы создаете игры прямо на сенсорном экране и загружаете их на наш облачный сервер.

Геймеры используют ленту в стиле Tik Tok для просмотра игр. Игры загружаются мгновенно. Это большая техническая проблема. И размер двоичного файла игры, и код загрузки должны быть максимально оптимизированы. Чтобы уменьшить исходный двоичный файл, мы храним данные в сильно сжатом виде и также опираемся на потоковую передачу.

HypeHype поддерживает многопользовательский режим до 8 игроков. Многопользовательские функции и количество игроков будут увеличиваться в будущем, как только будет развернута наша инфраструктура облачного игрового сервера.

У нас есть полнофункциональный редактор игр внутри мобильного приложения. Для написания игровой логики используется визуальная система сценариев. Игроки могут наблюдать за тем, как создатели создают игры, а несколько создателей могут совместно создавать игры в режиме реального времени. Это немного похоже на Google Docs, но для создания игр. Тестовая игра происходит мгновенно, и все зрители присоединяются к многопользовательскому тестовому сеансу в качестве игроков. Это значительно сокращает время итерации.

Конечно, у нас есть полный набор социальных функций, включая чат, таблицы лидеров, повторы и т. п.
_;
HypeHype в основном нацелен на мобильные устройства и планшеты. Но у нас также есть веб-клиент и собственные приложения для ПК и Mac.

У меня есть опыт разработки консолей в Ubisoft, поэтому мне нравится сравнивать мобильные устройства с предыдущими поколениями консолей, чтобы лучше их понять.

Xbox 360 и PS3 в настоящее время равны мобильным устройствам нижнего и среднего уровня по производительности графического процессора. Это отличная новость, поскольку эти консоли предлагают самый большой визуальный скачок, который мы видели между поколениями консолей до сих пор: мы получили разрешение вывода HD и смогли впервые реализовать надлежащие конвейеры освещения HDR, физически обоснованные модели материалов и постобработку изображений. Все это возможно сегодня на обычных мобильных устройствах. И мы можем масштабировать это до устройств нижнего уровня со скоростью 30 кадров в секунду с помощью масштабирования.

Если посмотреть на верхний уровень, то вы увидите, что последние телефоны за 1000 долларов и более уже достигли уровня производительности Xbox One и PS4. Однако эти телефоны работают на более высоком собственном разрешении и ограничены температурой, поэтому в реальности мы пока не можем достичь этого поколения визуальной точности на мобильных устройствах в реальных играх. И мы даже не хотим этого, так как это сделает устройства горячими и разрядит их батарею за пару часов.
_;
Игры HypeHype были ограничены простыми визуальными эффектами: стилизованные нетекстурированные объекты, простое гамма-пространственное освещение и крошечные сцены с небольшим расстоянием обзора. Это было нормально для простых гиперказуальных игр.

Однако это большое ограничение для платформы, поэтому мы начали создавать новый рендер с нуля год назад. Цель визуальной точности для нового рендера — соответствовать самым красивым играм Xbox 360 и PS3. Мы внедрим полный конвейер PBR с современными методами освещения, затенения и постобработки. Мы будем ориентироваться на более крупные игровые миры и более длинные расстояния прорисовки, чтобы позволить большему количеству игровых жанров правильно строиться на платформе. 

Это все хорошо, конечно, но мы должны быть очень осторожны с затратами производительности всех этих новых улучшений. Мы по-прежнему хотим запускать игры HypeHype с фиксированными 60 кадрами в секунду на мобильных телефонах среднего уровня без ограничения устройств. Это большая проблема для нас и главная причина, по которой мы уделяем большое внимание производительности в нашей новой архитектуре рендеринга.
_;
Если сравнить современные популярные телефоны с Xbox 360, то можно заметить много сходств. 

У обоих дизайнов медленная общая основная память. Основным ограничивающим фактором является пропускная способность. Оба дизайна также используют методы для снижения использования полосы пропускания памяти. 

Поскольку основная память медленная, вы хотите максимально избегать разрешения целей рендеринга. Вы хотите минимизировать количество проходов рендеринга. Выполнение нескольких задач одновременно — ключ к хорошей производительности. Современные мобильные телефоны также имеют сжатие буфера кадров для снижения разрешения цели рендеринга и стоимости полосы пропускания выборки. Это хорошее дополнение, но не решает проблему полностью. Сжатие текстур ASTC также помогает. Оно обеспечивает лучшее качество и меньший объем, чем DXT5 в свое время. 

У мобильных телефонов также есть математика fp16 с двойной скоростью. Это помогает, поскольку вы не хотите полагаться на поиск в памяти на устройствах с нехваткой полосы пропускания. И теперь доступны лучшие форматы буфера кадров HDR с более низкой точностью. 

Но некоторые старые ограничения все еще остаются: мобильные графические процессоры по-прежнему разрабатываются вокруг однородных буферов. Загрузка SSBO с динамических адресов все еще медленная. Если вы можете скаляризировать свои шаблоны доступа к памяти, вы достигаете наилучшего результата производительности. Это ограничивает алгоритмы, которые мы можем эффективно реализовать. Многие мобильные телефоны также записывают вершинные вариации в основную память, что стоит значительного количества драгоценной пропускной способности. Оптимизация размера вариаций является ключом к хорошей производительности на этих устройствах.
_;
Я говорил о GPU-управляемом рендеринге еще 8 лет назад на SIGGRAPH, мы представили основные идеи, такие как кластерный рендеринг и 2-проходное отсечение преград, которые в настоящее время стали фактическим стандартом.

Недавно Nanite от Epic сделала GPU-управляемый рендеринг доступным для мейнстрима. Они объединяют V-буфер, классификацию материалов, аналитические производные и программный растеризатор, чтобы сделать GPU-управляемый рендеринг достаточно надежным для универсального движка.

Однако все еще есть много нерешенных проблем производительности с GPU-управляемым рендерингом на основных мобильных GPU.

Мобильные GPU еще не оптимизированы для нагрузок SSBO. AMD и Nvidia оптимизировали свои пути данных пару поколений назад, когда добавили трассировку лучей. Модели доступа к трассировке лучей являются динамическими, и вы больше не можете полагаться на крошечные буферы на чипе для атрибутов вершин. Нам все еще нужно дождаться, когда мобильные GPU с похожей оптимизацией станут мейнстримом.
_;
Давайте поговорим о нашей дорожной карте. 

Мы разделили переписывание рендерера на два этапа. Сначала мы переписали низкоуровневый API gfx и весь платформенно-специфичный код бэкенда. Чтобы запустить как старый, так и новый бэкенды одновременно, мы вводим минимальную оболочку с ifdefs, чтобы мы могли продолжать поставлять старый код рендеринга и переключаться между новым и старым, чтобы сравнивать их. Мы уже удалили 200 файлов старого кода рендеринга и недавно начали сносить оболочку и заменять ее прямыми вызовами нового API платформы. 

Эта презентация будет посвящена низкоуровневому API платформы и бэкендам. Позже я расскажу о нашем новом высокоуровневом коде рендеринга. Наш дизайн позволяет нам реорганизовывать эти части совершенно независимо друг от друга. Я вернусь к этой теме позже в презентации.
_;
Первое, что нам нужно решить, — это уровень абстракции платформы. Какой код специфичен для платформы, а какой — не специфичен для платформы.

Игровые движки обычно ограничивают специфичный для платформы код самыми нижними уровнями стека. Это минимизирует объем кода, специфичного для платформы, и снижает затраты на реализацию и обслуживание. Однако некоторые особенности движка и рендерера имеют тенденцию просачиваться в код платформы самого низкого уровня.

Если посмотреть на мобильные приложения, то специфичный для платформы код, как правило, достигает немного более высоких уровней в стеке. Например, популярный фреймворк приложений Google Flutter разрабатывается несколькими специфичными для платформы командами. Обычно они сначала выпускают новые функции на мобильные устройства, а затем на настольные компьютеры. Android и iOS также не имеют полного паритета функций. Их высокоуровневый код рендеринга отличается на настольных и мобильных платформах, включая Mac и iOS, хотя они обе используют один и тот же API Metal. 

Многие мобильные приложения еще больше увеличивают разделение кода. Часто есть совершенно отдельные команды iOS и Android со своими выделенными базами кода. 
_;
Мы хотим как можно меньшего количества платформенно-специфичного кода. Это приводит к дизайну, в котором мы плотно оборачиваем существующие низкоуровневые API gfx. 

Работа над дизайном началась с перекрестных ссылок на документы Vulkan, Metal и WebGPU. Я уже был знаком со всеми этими API, что упростило работу и сделало ее менее подверженной ошибкам. 

При написании оболочки сначала нужно найти общий набор функций. Их часто легко оборачиват. Трудности возникают, когда в дизайне API есть различия. Необходимо проявлять осторожность, чтобы абстрагировать эти различия таким образом, чтобы обеспечить оптимальную производительность. Мы решили использовать Metal 2.0, потому что он ближе к Vulkan и WebGPU и предоставляет кучи размещения, буферы аргументов и ручные ограждения, что позволяет нам извлечь немного больше производительности из устройств Apple.
_;
Давайте поговорим о целях проектирования этого нового API платформы. 

Во-первых, мы хотим, чтобы это была автономная библиотека. Разработанная и поддерживаемая независимо от движка HypeHype. Она должна иметь стабильный API, который не меняется часто.

За свою карьеру я видел много абстракций графических платформ, и проблема большинства абстракций заключается в том, что концепции пользовательской земли проникают в аппаратный API. Наличие сетки и материала в коде платформы является наиболее распространенной проблемой. Это проблематично, поскольку и сетка, и материал подвержены давлению изменений. Мешлеты и текстуры без привязок — это будущее. Мы не хотим привязываться к определенному способу их представления. Сетка может быть просто представлена ​​как привязка буфера индексов + привязки буфера вершин N, а материал может быть представлен как группа привязок, содержащая несколько дескрипторов текстур и буфер для данных значений.
_;
Итак, у нас очень строгие стандарты производительности для нашего API, но в то же время мы хотим, чтобы он был таким же простым в использовании, как DX11. Как этого добиться?

Нам нужен хороший процесс проектирования API. 

Традиционным способом было бы потратить месяцы на изучение документации API и написание большого технического документа по проектированию, подробно описывающего новый API, разбивающего его на задачи и оценивающего время реализации каждой задачи для каждого бэкенда. 

Проблема с этим подходом заключается в том, что вы фиксируете дизайн слишком рано, и его трудно изменить позже. Небольшие мельчайшие детали имеют большое значение в графическом коде, специфичном для платформы. Вы не можете по-настоящему понять влияние на производительность всех пограничных случаев, не написав никакого кода. Теперь вы заметите эти проблемы, когда будет написано много готового к производству кода. На этом этапе слишком сложно оправдать полное переписывание планов и кода.
_;
Наше решение этой проблемы — использовать высоко итеративный процесс проектирования. 

Я начинаю с написания кода макета пользовательской земли. Этот API пока не существует, но я продолжаю писать макет кода, пока он меня не устроит. Я пишу код для создания всех ресурсов, которые мне нужны для рендеринга, текстур, шейдеров, буферов и т. д., а затем пишу небольшой цикл отрисовки с использованием этих ресурсов. Цикл отрисовки вызывается несколько раз, при этом некоторые ресурсы мутируют для реализации анимации. Важно заранее спроектировать как динамические, так и статические пути данных.

Как только я буду доволен первой итерацией кода пользовательской земли, я пишу для него API макета платформы. На данный момент это просто пустой API. Реализации бэкэнда нет. Но он позволяет мне начать использовать компилятор для проверки синтаксиса и автодополнения. Теперь я действительно могу начать экспериментировать с API, чтобы увидеть, насколько он удобен в использовании.

Затем я проведу проверку производительности для всего кода пользовательской земли. Я хорошо понимаю, как работают все API платформы, поэтому я думаю, какой тип реализации каждого вызова API потребуется в бэкендах Vulkan, Metal и WebGPU. Если реализация тривиальна, то все в порядке. Если реализация требует дополнительных копий данных, поиска в хэш-картах, выделения памяти или других дорогостоящих операций, то я отбрасываю этот дизайн и переписываю эту часть API, чтобы она была более эффективной. Как вы помните, наша цель — быть такими же быстрыми, как оптимизированный вручную DX12 в каждом отдельном случае. Мы не сможем этого сделать, если наш API не будет идеально соответствовать базовому аппаратному API.
_;
Последняя тема о проектировании API, которую я хотел обсудить сегодня, — это выполнение вещей с правильной частотой и детализацией.

Большой проблемой при рендеринге кода, как правило, является то, что дорогостоящие операции выполняются со слишком высокой частотой. Это также приводит к увеличению затрат на отслеживание в цикле горячей отрисовки.

В играх много временной согласованности. Вы загружаете игровой мир и медленно изменяете его в каждом кадре. Большая часть данных остается прежней. Кроме того, камера большую часть времени движется медленно. Человеческому мозгу нужна временная согласованность между кадрами, чтобы видеть плавное движение. Это здорово для нас! Мы хотим это использовать!

Давайте посмотрим на все происходящее: Загрузка игрового мира и всех шейдерных PSO происходит в начале. Если у вас более крупный уровень, вы также загружаете текстуры, сетки и материалы при перемещении. Большинство объектов появляются в начале, но разделы уровня могут появляться во время потоковой передачи, враги, добыча, снаряды и т. д. обычно появляются на протяжении всей игры, но не так много в каждом кадре. Единственная действительно высокочастотная операция — это отбраковка всех объектов и отрисовка видимых объектов. Циклы отбраковки и отрисовки — самые чувствительные ко времени циклы во всей вашей кодовой базе.
_;
Наше решение этой проблемы — полностью отделить все изменения данных от рисования. Все данные готовы до цикла рисования.

Объекты состояния конвейера (PSO) должны быть созданы при запуске приложения или во время загрузки уровня. Создание PSO во время выполнения приводит к подтормаживанию. В нашей философии варианты шейдеров создаются кодерами и техническими художниками и оптимизируются вручную. Их существует лишь ограниченное количество. Это похоже на то, что делает id-Software, и обеспечивает очень хорошую производительность. 

Мы сохраняем дескриптор PSO непосредственно в визуальном компоненте каждого объекта. Нам не нужны поиски в хэш-карте, чтобы получать его в каждом кадре.

Мы предварительно создаем все группы привязок (наборы дескрипторов). Наборы дескрипторов материалов содержат все их текстуры и буфер для данных значений. Мы сохраняем дескриптор группы привязок материалов в визуальном компоненте объектов. Это позволяет избежать поиска в хэш-карте и позволяет эффективно изменять привязки материалов с помощью одной команды Vulkan, Metal и WebGPU.

Важно разделять постоянные и динамические данные. Постоянные данные загружаются при запуске, а дельта обновляется при изменении. Я выступал на эту тему два года назад на REAC 2011. Вы можете обратиться к этой презентации, если хотите узнать больше информации по этой теме.

Динамические данные должны загружаться пакетно один раз за проход вместо использования map/unmap на вызов отрисовки. Глобальные данные должны быть отделены от данных по отрисовке, чтобы минимизировать непроизводительные затраты на полосу пропускания.
_;
И теперь мы готовы обсудить детали реализации.

Для рендеринга нужны текстуры, буферы, шейдеры и несколько других объектов ресурсов. Нам нужен хороший способ хранить эти объекты и гарантировать их безопасность в использовании. 

Современная практика C++ заключается в использовании интеллектуальных указателей, подсчета ссылок и RAII (получение ресурсов — это инициализация). 

Честно говоря, это слишком медленно для нас. Интеллектуальные указатели с подсчетом ссылок связывают время жизни ссылки и резервной памяти вместе. Это приводит к большому количеству небольших выделений памяти. Выделение памяти обходится дорого в современных многопоточных системах. Выделения также случайным образом разбросаны по системной памяти, что ухудшает шаблоны доступа к данным и увеличивает промахи кэша. Копирование интеллектуальных указателей с подсчетом ссылок требует двух атомарных операций (add, sub), поскольку мы находимся в многопоточной системе. Владение может быть разделено между потоками.

Также есть проблемы с безопасностью. Подсчет ссылок делает время жизни объекта неопределенным. Трудно рассуждать об этом. Он может умереть в любом потоке. Такие объекты RAII, как слушатели, вызывают побочные эффекты деструкторов.
_;
Чтобы решить эту проблему, нам нужно заменить индексы массива на генерационные дескрипторы. Давайте обсудим, что это значит.

Пул похож на наш массив данных. Это типизированный массив объектов, но теперь он также имеет дополнительный массив счетчика поколений. Счетчик поколений сообщает, сколько раз слот был повторно использован. Счетчик увеличивается, когда текущие данные в этом слоте освобождаются.

У нас также есть список свободных мест в пуле. Список свободных мест — это просто линейный массив, содержащий индексы каждого свободного слота. Он имеет семантику стека. Когда вы выделяете новый объект, вы выталкиваете свободный индекс сверху. Когда вы удаляете объект, вы помещаете индекс освобожденного слота наверх свободного списка. Это обе быстрые операции O(1). Когда свободный список заканчивается, мы удваиваем размер пула. Это безопасно, так как никому не разрешено иметь прямые ссылки указателя на данные в массиве. Все ссылки выполняются с помощью дескрипторов.

Дескриптор — это просто структура POD. Он содержит индекс массива, как и на предыдущем слайде, но теперь у нас также есть счетчик поколений рядом с ним. Это в общей сложности 32 бита (например, 16+16 битное разделение) или 64 бита (32 + 32 бита), в зависимости от того, сколько одновременно активных ресурсов вам требуется и насколько короткое время жизни объектов. В HypeHype мы используем 32-битные (16+16) дескрипторы для всех графических ресурсов, этого достаточно для 65536 ресурсов каждого конкретного типа.
_;
Одной из наших главных целей было сделать API таким же простым в использовании, как DX11. Для этого нам нужно объединить вспомогательные данные в наши структуры данных в пулах. В Vulkan дескриптор VkTexture ничего не знает о себе, что раздражает, если вы пытаетесь написать свой код рендеринга на чистом Vulkan. Мы хотим, чтобы наша структура текстуры знала свой размер, формат, указатель данных для записи, распределитель для удаления и так далее. 

Эти вспомогательные данные требуются для низкочастотных задач, таких как изменение ресурса и удаление ресурса. Поскольку наш принцип проектирования заключается в разделении изменений ресурсов от рисования, мы получаем доступ к этим данным только при изменении или удалении ресурса. Это означает, что размещение вспомогательных данных в той же структуре, что и данные, необходимые в цикле горячей отрисовки, неэффективно с точки зрения кэширования. Цикл отрисовки будет загружать данные в L1$, которые не используются. Я ненавижу компромиссы между производительностью и удобством использования. 

Наше решение этой проблемы — использовать макет SoA внутри пулов. Мы определяем, какие данные требуются в каждом кадре в циклах горячей отрисовки, и помещаем эти данные в одну структуру, а оставшиеся низкочастотные вспомогательные данные — в другую структуру. Теперь в пуле два массива данных вместо одного. Мы можем использовать тот же индекс массива в дескрипторе для доступа к любому из массивов данных (или к обоим). Таким образом, нам нужно загружать горячие данные в кэши только в цикле отрисовки, критическом для производительности.
_;
Теперь у нас есть хороший способ хранить и ссылаться на графические ресурсы. Следующая тема — создание ресурсов.

Создание графических ресурсов в Vulkan и DX12 — обременительное занятие. Вам нужно заполнять большие структуры, которые содержат другие большие структуры. Некоторые из этих структур также содержат указатели на массивы структур. Это позволяет выстрелить себе в ногу временными сроками жизни объектов.

Наиболее распространенным существующим решением этой проблемы является использование шаблона строителя для дескрипторов ресурсов: объект строителя содержит хорошее состояние по умолчанию для дескриптора. Он предлагает API для мутации самого себя, чтобы задать все поля, которые вы хотите изменить. Когда вы будете готовы, вы вызываете функцию сборки, чтобы получить окончательную структуру дескриптора. Это легко использовать, но кодогенерация, особенно в режиме отладки, далека от совершенства. В HypeHype мы часто используем режим отладки во время разработки, поэтому мы хотим, чтобы он был быстрым. 

Наше решение этой проблемы — использовать назначенные инициализаторы структур C++20 в сочетании с агрегатной инициализацией структур C++11. Эти две функции в сочетании позволяют нам устанавливать значения по умолчанию для каждой структуры тривиальным способом. 
_;
Вот как это выглядит на практике. 

Давайте начнем с левой стороны: сначала мы создаем буфер вершин и текстуру. Синтаксис здесь хороший, и мы объявляем только поля, которые отличаются от значений по умолчанию структуры. 

Если вы посмотрите на левый нижний угол, вы увидите, что мы объявляем материал. Это группа связывания. Группа связывания имеет массив текстур: альбедо, нормаль и свойства. Мы используем здесь список инициализаторов для предоставления массива. Это делает синтаксис очень чистым. И стоит отметить, что этот массив не требует выделения кучи. Список инициализаторов и вся структура дескриптора находятся в стеке. Они никогда не копируются. Мы просто передаем ссылку на них в вызове функции создания ресурса. Это так же быстро, как сырой DX12 или сырой Vulkan. 

С правой стороны вы видите, как мы инициализируем более сложный ресурс. Это немного похоже на json. Мы именованные поля, массивы и поля и массивы внутри друг друга с правильным отступом. Это гораздо проще писать и читать по сравнению с сырым DX12 и Vulkan. И все же мы не платим за время выполнения. Все еще нет выделения памяти или копирования данных. Все это чистые данные стека.
_;
Теперь, когда у нас есть хороший способ создания и хранения ресурсов, нам нужно выделить для них память GPU.

Я предпочитаю использовать временную память, когда это возможно. Временная память не фрагментирует ваши пулы памяти, и ее выделение так же просто, как добавление числа к счетчику.

Мы используем кучи памяти размером 128 МБ в нашем распределителе выступов. Кучи хранятся в кольце. Если распределитель выступов достигает хвоста, мы выделяем новый блок кучи. Как только мы достигаем стабильного состояния, выделения кучи вообще не происходит. Мы создаем платформенно-специфичный буферный дескриптор для каждой создаваемой нами кучи GPU. Этот буферный дескриптор отображает всю кучу. Таким образом, нам не нужно создавать платформенно-специфичные буферные объекты во время выполнения. Наша структура буфера просто содержит индекс кучи и смещение. Очень эффективно создавать их во время выполнения и передавать пользователю.

В качестве дополнительной оптимизации мы предоставляем пользователю конкретный объект распределителя выступов. Он имеет функцию для выделения N байт. Эта функция идеально встраивается в вызывающую функцию. Она просто увеличивает счетчик, а затем проверяет, находится ли счетчик за пределами блока кучи. Эта проверка является предсказуемым переходом. Когда блок заканчивается, мы вызываем виртуальную функцию в API gfx, чтобы получить новый блок временного распределителя. Это происходит только один раз для 128 МБ данных, что делает его очень эффективным.
_;
Одно из самых больших отличий нашего дизайна от других рендереров — это группы привязок пользовательской земли (наборы дескрипторов в терминологии Vulkan).

Традиционный способ — иметь отдельные привязки для каждой текстуры и буфера. Перед рисованием вы устанавливаете все привязки отдельно. Бэкэнд GFX должен объединить эти привязки в специфической для шейдера компоновке и создать соответствующие группы привязок (WebGPU), наборы дескрипторов (Vulkan), буферы аргументов (Metal) или таблицы дескрипторов (DX12). Эти объекты групп привязок являются объектами GPU и требуют больших затрат на создание. IHV рекомендуют вам предварительно создавать все объекты GPU, чтобы избежать проблем с зависаниями и фрагментацией памяти.

Обычный обходной путь — кэшировать группы привязок в хэш-карте в бэкэнде. Все привязки хэшируются, и выполняется поиск. Если группа привязок существует, то она используется повторно, а не создается. Проблема с этим подходом заключается в том, что хэширование требует больших затрат, а поиск в хэш-карте рандомизирует ваш шаблон доступа к памяти. Если вы выполняете рендеринг из нескольких потоков, вам может даже потребоваться защитить хэш группы привязки с помощью мьютекса, что сделает его еще более затратным. 

Наше решение — перенести группы привязки непосредственно в пользовательскую область: пользователь заранее создает неизменяемые группы привязки. Например, группа привязки материала содержит 5 текстур и один унифицированный буфер (заполненный данными значений). Вы получаете дескриптор, который используете для привязки материала.
_;
Я уже говорил, что буферы программных команд медленные, но у нас есть один :)

Этот буфер программных команд полностью отличается от тех, с которыми большинство людей знакомы. У нас нет никаких данных в буфере программных команд. У нас есть только метаданные, указывающие на уже загруженные данные. Метаданные также сгруппированы, что делает их намного меньше, чем отдельные привязки и отдельные состояния. Это позволяет нам представлять вызов отрисовки всего с 64 байтами данных, что является всего одной строкой кэша ЦП.

Наш первоначальный проект заключался в использовании массива структур отрисовки. Структура отрисовки содержит дескрипторы шейдера (это разрешенный вариант PSO, включающий все состояние рендеринга), 3 группы привязок пользовательских земель, динамические буферы (для временно выделенных данных смещения), буферы индексов и вершин и некоторые смещения. Смещения необходимы, поскольку подвыделение ресурсов обычно дает большой выигрыш в производительности.
_;
Идея заключается в том, чтобы хранить только те поля, которые изменяются. Это приводит к дизайну потока отрисовки.

Мы сохраняем 32-битную битовую маску перед каждым вызовом отрисовки. Эта битовая маска сообщает, какие поля в структуре отрисовки изменились.

Код пользовательской земли отвечает за запись данных в соответствии с контрактом API потоковых данных. Для этого у нас есть класс записи потока отрисовки пользовательской земли. Он содержит одну структуру отрисовки, описывающую текущее состояние, и грязную маску. Запись потока отрисовки предоставляет функцию для установки каждого поля в структуре. Эти функции проверяют, было ли изменено значение данных. Если да, то устанавливают соответствующий грязный бит и записывают это поле в поток. После записи всех полей пользователь вызывает отрисовку, которая просто записывает грязную битовую маску перед значениями данных.

Бэкенд прост: для каждого вызова отрисовки он считывает грязную битовую маску. Затем он считывает один uint32 из потока для каждого бита и вызывает соответствующий вызов API платформы, чтобы установить эту привязку/состояние/значение. Преимущество этой конструкции в том, что бэкэнду не нужна никакая фильтрация состояния. Мы уже сделали это в коде пользовательской земли. Это удобно на платформах, где вторичные буферы команд недоступны или работают медленно (некоторые графические процессоры Qualcomm отключают оптимизацию с вторичными буферами команд). Мы по-прежнему можем генерировать поток отрисовки с использованием нескольких рабочих потоков и разгружать там затраты на фильтрацию состояния. Поток рендеринга работает максимально быстро, что является большим выигрышем, поскольку вызовы API платформы работают медленно на мобильных устройствах. Мы также экономим примерно в 3 раза пропускную способность по сравнению с полноценными 64-байтовыми структурами.
_;
Давайте поговорим о производительности вызова отрисовки. 

Этот слайд представляет собой довольно традиционный цикл отрисовки в стиле DX11 и OpenGL. Для каждого вызова отрисовки мы вызываем map/unmap и записываем uniform-переменные отдельно. Мы также привязываем буфер вершин и буфер индексов, а также привязываем наши текстуры и буферы. Здесь я просто привязываю набор 2 (материал) и набор 3, следуя принятым у нас соглашениям. 

Всего это 6–7 вызовов API на вызов отрисовки. 6 вызовов, когда материал не меняется, и 7 в противном случае. Если мы сортируем по материалу, то можем предположить, что число ближе к 6, чем к 7.
_;
Это использование временного распределителя для увеличения выделения униформ (и других динамических данных). Теперь нам не нужно вызывать map/unmap на вызов отрисовки. Это сокращает количество вызовов API до 4-5 на вызов отрисовки.

Map/unmap — это на удивление дорогие вызовы. Наш старый бэкэнд GLES загружал униформы на вызов отрисовки. Самым большим отличием в нашем новом бэкэнде GLES3 (WebGL2) было отсутствие map/unmap на отрисовку, и это изменение само по себе дало нам около 3-кратного прироста производительности ЦП. 

Мы не реализовали map/unmap на отрисовку в нашем новом бэкэнде Vulkan (Vulkan поддерживает постоянное отображение), поэтому я, к сожалению, не могу показать вам здесь цифры Vulkan.
_;
Следующей оптимизацией с большим эффектом стала упаковка сеток. Мы выделяем большие блоки кучи по 128 МБ и имеем один дескриптор буфера платформы для каждого. Это позволяет нам легко перераспределять сетки и просто изменять базовую вершину и базовый индекс в каждом вызове отрисовки для изменения сетки. 

Таким образом, мы избавляемся от двух вызовов API: установить буфер вершин и установить буфер индекса. Мы сократили до 2-3 вызовов API на отрисовку, что очень здорово!

Эта оптимизация улучшила пропускную способность ЦП на всех устройствах. Мы увидели наибольший прирост на настольных графических процессорах (почти в 2 раза), но мобильные графические процессоры также показали заметный прирост (30%-40%).
_;
Последняя оптимизация, которую я хочу обсудить, — это базовый экземпляр.

Базовый экземпляр рисования использует ту же компоновку данных, что и экземпляр. Вы используете плотно упакованный массив данных рисования. На мобильных устройствах унифицированные буферы имеют ограничение на размер привязки в 16 КБ. Идея состоит в том, чтобы изменять смещение привязки один раз на каждые 16 КБ, амортизируя стоимость повторной привязки буфера временного распределителя с другим смещением. Это сокращает количество вызовов API на 1, и теперь у нас есть оптимальное количество вызовов API: только сама отрисовка и возможное изменение группы привязки материалов. Вызов отрисовки имеет параметр базового экземпляра, который мы меняем, чтобы он указывал на другой слот в массиве данных унифицированного буфера.

Так почему бы вместо этого не использовать экземплярирование? Базовый экземпляр приводит к лучшей генерации кода шейдера на многих платформах. Причина в том, что идентификатор экземпляра является динамическим смещением. Графические процессоры упаковывают несколько экземпляров в одну и ту же вершинную волну, что означает, что все данные, индексированные по идентификатору экземпляра, должны использовать векторные регистры и векторные загрузки. Это сильно раздувает регистры для загрузки матриц 4x4 и т. п. С другой стороны, базовый экземпляр — это статическое смещение на отрисовку. Каждая полоса загружается из одного и того же места. Это означает, что компиляторы могут скаляризировать пути кода и/или использовать быстрое оборудование постоянного буфера. 

Однако на практике мы сталкиваемся с различными проблемами. В то время как базовый экземпляр кодогенерации идеален на ПК, на мобильных графических процессорах это смешанная картина. Некоторые драйверы просто не оптимизируют это должным образом. Кроме того, эта функция имеет плохое покрытие.
_;
Давайте взглянем на показатели производительности. 

Это с использованием одного потока рендеринга. Десять тысяч реальных вызовов отрисовки без каких-либо трюков с созданием экземпляров. Каждый вызов отрисовки использует уникальную сетку и уникальный материал. С группами привязки и упакованными сетками можно быстро менять материал и сетку. 

У меня еще не было времени реализовать данные сцены, сохраняющиеся на GPU, в HypeHype. Эти цифры с выделенными униформами для каждой отрисовки, как описано на предыдущих слайдах. 

Мы нацелены на 10 тыс. вызовов отрисовки, потому что это то, что нам удалось продвинуть 15 лет назад с Xbox 360 при 60 кадрах в секунду. И результаты впечатляют. Даже недорогие телефоны Android за 99 долларов близки к достижению 60 кадров в секунду в этом стресс-тесте. В реальной игровой сцене с набором UGC у нас будет много повторяющихся сеток и материалов, что позволит выполнять пакетную обработку и сокращать количество вызовов API gfx. Мы также намерены сделать рендеринг многопоточным. 

На современных интегрированных графических процессорах AMD (также в Steam Deck и ROG Ally handheld) наш рендерер может выдавать 10 тыс. отрисовок менее чем за одну миллисекунду. При использовании многопоточности наш рендерер может выдавать до 1 млн вызовов отрисовки со скоростью 60 кадров в секунду на современных графических процессорах AMD и Nvidia.
_;
Ну вот и всё, дорогие друзья! Если захочется что-то почитать, то обратите внимание на список литературы. Здесь также приведены ссылки на информацию, которой я оперировал в своем выступлении.
_;
Всем до встречи, используйте видеокарточки Nvidia